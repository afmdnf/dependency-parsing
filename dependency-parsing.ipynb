{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,re\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from scipy import sparse\n",
    "from collections import Counter\n",
    "from sklearn import grid_search\n",
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_REGULARIZATION_STRENGTH = 1e0\n",
    "MINIMUM_FEAT_COUNT=5\n",
    "\n",
    "# dictionary of feature: index\n",
    "# feature = a dictionary of feature name: value\n",
    "feature_vocab={}\n",
    "\n",
    "# reverse_features[index] = feature\n",
    "reverse_features=[]\n",
    "\n",
    "# dictionary of label: index, where\n",
    "# label = SHIFT, LEFTARC_DEPENDENCY_LABEL, RIGHTARC_DEPENDENCY_LABEL\n",
    "label_vocab={}\n",
    "\n",
    "# reverse_labels[index] = label\n",
    "reverse_labels=[]\n",
    "\n",
    "# number/ID of features\n",
    "fmax = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Checking for Projectivity\n",
    "“An arc from a head to a dependent is said to be projective if there is a path from the head to every word that lies between the head and the dependent in the sentence. A dependency tree is then said to be projective if all the arcs that make it up are projective.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_connected(i, head, heads):\n",
    "    prev = i\n",
    "    while prev != 0:\n",
    "        prev = heads[prev]\n",
    "        if prev == head:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_projective(toks):\n",
    "    \"\"\"\n",
    "    params: toks is a list of (idd, tok, pos, head, lab) for a sentence\n",
    "    return True if and only if the sentence has a projective dependency tree\n",
    "    \"\"\"\n",
    "    heads = {}\n",
    "    for x in toks:\n",
    "        idd = x[0]\n",
    "        if idd not in heads:\n",
    "            heads[idd] = x[3]\n",
    "    for depend in heads:\n",
    "        head = heads[depend]\n",
    "        for i in range(1 + min(head, depend), max(head, depend)):\n",
    "            if not is_connected(i, head, heads):\n",
    "                return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Creating an Oracle\n",
    "Following is the implementation of the training oracle, which transforms the input dependency trees (lists of\n",
    "(idd, tok, pos, head, lab) tuples) to (configuration, action) pairs in `tree_to_actions`. The helper functions `perform_shift` and `perform_arc` generate the proper configuration and action for the corresponding SHIFT, LEFTARC and RIGHTARC operations, and update the states of the stack, input buffer and arcs as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_shift(wbuffer, stack, arcs,\n",
    "                  configurations, gold_transitions):\n",
    "    \"\"\"\n",
    "    perform the SHIFT operation\n",
    "    \"\"\"\n",
    "    # 1. append the latest configuration to configurations\n",
    "    configurations.append((list(wbuffer), list(stack), list(arcs)))\n",
    "    \n",
    "    # 2. append the latest action to gold_transitions\n",
    "    gold_transitions.append(\"SHIFT\")\n",
    "    \n",
    "    # 3. update wbuffer, stack and arcs accordingly\n",
    "    stack.append(wbuffer.pop())\n",
    "\n",
    "def perform_arc(direction, dep_label,\n",
    "                wbuffer, stack, arcs,\n",
    "                configurations, gold_transitions):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        - direction: {\"LEFT\", \"RIGHT\"}\n",
    "        - dep_label: label for the dependency relations\n",
    "    Perform LEFTARC_ and RIGHTARC_ operations\n",
    "    \"\"\"\n",
    "    # 1. append the latest configuration to configurations\n",
    "    configurations.append((list(wbuffer), list(stack), list(arcs)))\n",
    "    \n",
    "    # 2. append the latest action to gold_transitions\n",
    "    gold_transitions.append(\"{}ARC_{}\".format(direction, dep_label))\n",
    "    \n",
    "    # 3. update wbuffer, stack and arcs accordingly\n",
    "    if direction == \"RIGHT\":\n",
    "        arcs.append((dep_label, stack[-2], stack[-1]))\n",
    "        stack.pop()\n",
    "    else:\n",
    "        arcs.append((dep_label, stack[-1], stack[-2]))\n",
    "        stack.pop(-2)\n",
    "    \n",
    "\n",
    "def tree_to_actions(wbuffer, stack, arcs, deps):\n",
    "    \"\"\"\n",
    "    params:\n",
    "    wbuffer: a list of word indices, top of buffer is at the end of the list\n",
    "    stack: a list of word indices, top of buffer is at the end of the list\n",
    "    arcs: a list of (label, head, dependent) tuples\n",
    "\n",
    "    Given wbuffer, stack, arcs and deps\n",
    "    Return configurations and gold_transitions (actions)\n",
    "    \"\"\"\n",
    "    # configurations:\n",
    "    # A list of tuples of lists\n",
    "    # [(wbuffer1, stack1, arcs1), (wbuffer2, stack2, arcs2), ...]\n",
    "    # Keeps tracks of the states at each step\n",
    "    configurations=[]\n",
    "\n",
    "    # gold_transitions:\n",
    "    # A list of action strings, e.g [\"SHIFT\", \"LEFTARC_nsubj\"]\n",
    "    # Keeps tracks of the actions at each step\n",
    "    gold_transitions=[]\n",
    "    \n",
    "    depend = {}\n",
    "    while len(wbuffer) >= 0:\n",
    "        if len(wbuffer) == 0 and len(stack) == 1 and stack[0] == 0: # done\n",
    "            return configurations, gold_transitions\n",
    "        if len(stack) < 2 and len(wbuffer) > 0: # have to shift\n",
    "            perform_shift(wbuffer, stack, arcs, configurations, gold_transitions)\n",
    "            continue\n",
    "            \n",
    "        elem1, elem2 = stack[-1], stack[-2]\n",
    "        if elem1 in deps and (elem1, elem2) in deps[elem1]: # left\n",
    "            perform_arc(\"LEFT\", deps[elem1][(elem1, elem2)], wbuffer, stack, arcs, configurations, gold_transitions)\n",
    "            depend[elem2] = 1\n",
    "\n",
    "        elif elem2 in deps and (elem2, elem1) in deps[elem2]: # right, but check if assigned first\n",
    "            if elem1 in deps and any([child not in depend for _, child in deps[elem1]]):\n",
    "                perform_shift(wbuffer, stack, arcs, configurations, gold_transitions)\n",
    "            else:\n",
    "                perform_arc(\"RIGHT\", deps[elem2][(elem2, elem1)], wbuffer, stack, arcs, configurations, gold_transitions)\n",
    "                depend[elem1] = 1      \n",
    "\n",
    "        else:\n",
    "            perform_shift(wbuffer, stack, arcs, configurations, gold_transitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Tree Parsing with Predictions\n",
    "`action_to_tree` updates the dependency tree based on the action predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isvalid(stack, wbuffer, action):\n",
    "    \"\"\"\n",
    "    Helper function that returns True only if an action is\n",
    "    legal given the current states of the stack and wbuffer\n",
    "    \"\"\"\n",
    "    if action == \"SHIFT\" and len(wbuffer) > 0:\n",
    "        return True\n",
    "    if action.startswith(\"RIGHTARC\") and len(stack) > 1 and stack[-1] != 0:\n",
    "        return True\n",
    "    if action.startswith(\"LEFTARC\") and len(stack) > 1 and stack[-2] != 0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def action_to_tree(tree, predictions, wbuffer, stack, arcs):\n",
    "    \"\"\"\n",
    "    params:\n",
    "    tree:\n",
    "    a dictionary of dependency relations (head, dep_label)\n",
    "        {\n",
    "            child1: (head1, dep_lebel1),\n",
    "            child2: (head2, dep_label2), ...\n",
    "        }\n",
    "\n",
    "    predictions:\n",
    "    a numpy column vector of probabilities for different dependency labels\n",
    "    as ordered by the global variable reverse_labels\n",
    "    predictions.shape = (1, total number of dependency labels)\n",
    "\n",
    "    wbuffer: a list of word indices, top of buffer is at the end of the list\n",
    "    stack: a list of word indices, top of buffer is at the end of the list\n",
    "    arcs: a list of (label, head, dependent) tuples\n",
    "    \"\"\"\n",
    "    global reverse_labels\n",
    "    for prob in np.argsort(-predictions, kind='quicksort')[0]:\n",
    "        action = reverse_labels[prob]\n",
    "        if isvalid(stack, wbuffer, action):\n",
    "            if action == \"SHIFT\":\n",
    "                stack.append(wbuffer.pop())\n",
    "            elif action.startswith(\"LEFTARC_\"):\n",
    "                tree[stack[-2]] = (stack[-1], action.split(\"_\")[1])\n",
    "                stack.pop(-2)\n",
    "            elif action.startswith(\"RIGHTARC_\"):\n",
    "                tree[stack[-1]] = (stack[-2], action.split(\"_\")[1])\n",
    "                stack.pop()\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oracle(toks):\n",
    "    \"\"\"\n",
    "    Return pairs of configurations + gold transitions (actions)\n",
    "    from training data\n",
    "    configuration = a list of tuple of:\n",
    "        - buffer (top of buffer is at the end of the list)\n",
    "        - stack (top of buffer is at the end of the list)\n",
    "        - arcs (a list of (label, head, dependent) tuples)\n",
    "    gold transitions = a list of actions, e.g. SHIFT\n",
    "    \"\"\"\n",
    "    stack = [] # stack\n",
    "    arcs = [] # existing list of arcs\n",
    "    wbuffer = [] # input buffer\n",
    "\n",
    "    # deps is a dictionary of head: dependency relations, where\n",
    "    # dependency relations is a dictionary of the (head, child): label\n",
    "    # deps = {head1:{\n",
    "    #               (head1, child1):dependency_label1,\n",
    "    #               (head1, child2):dependency_label2\n",
    "    #              }\n",
    "    #         head2:{\n",
    "    #               (head2, child3):dependency_label3,\n",
    "    #               (head2, child4):dependency_label4\n",
    "    #              }\n",
    "    #         }\n",
    "    deps = {}\n",
    "\n",
    "    # ROOT\n",
    "    stack.append(0)\n",
    "\n",
    "    # initialize variables\n",
    "    for position in reversed(toks):\n",
    "        (idd, _, _, head, lab) = position\n",
    "\n",
    "        dep = (head, idd)\n",
    "        if head not in deps:\n",
    "            deps[head] = {}\n",
    "        deps[head][dep] = lab\n",
    "\n",
    "        wbuffer.append(idd)\n",
    "\n",
    "    # configurations:\n",
    "    # A list of (wbuffer, stack, arcs)\n",
    "    # Keeps tracks of the states at each step\n",
    "    # gold_transitions:\n",
    "    # A list of action strings [\"SHIFT\", \"LEFTARC_nsubj\"]\n",
    "    # Keeps tracks of the actions at each step\n",
    "    configurations, gold_transitions = tree_to_actions(wbuffer, stack, arcs, deps)\n",
    "    return configurations, gold_transitions\n",
    "\n",
    "def featurize_configuration(configuration, tokens, postags):\n",
    "    \"\"\"\n",
    "    Given configurations of the stack, input buffer and arcs,\n",
    "    words of the sentence and POS tags of the words,\n",
    "    return some features\n",
    "    \"\"\"\n",
    "    wbuffer, stack, arcs = configuration\n",
    "    feats = {}\n",
    "\n",
    "    feats[\"%s_%s\" % (\"len_buffer\", len(wbuffer))] = 1\n",
    "    feats[\"%s_%s\" % (\"len_stack\", len(stack))] = 1\n",
    "\n",
    "    # single-word features\n",
    "    if len(stack) > 0:\n",
    "        feats[\"%s_%s\" % (\"stack_word_1\", tokens[stack[-1]])] = 1\n",
    "        feats[\"%s_%s\" % (\"stack_tag_1\", postags[stack[-1]])] = 1\n",
    "        feats[\"%s_%s_%s\" % (\"stack_tag_word_1\", tokens[stack[-1]], postags[stack[-1]])] = 1\n",
    "\n",
    "    if len(stack) > 1:\n",
    "        feats[\"%s_%s\" % (\"stack_word_2\", tokens[stack[-2]])] = 1\n",
    "        feats[\"%s_%s\" % (\"stack_tag_2\", postags[stack[-2]])] = 1\n",
    "        feats[\"%s_%s_%s\" % (\"stack_tag_word_2\", tokens[stack[-2]], postags[stack[-2]])] = 1\n",
    "\n",
    "    if len(wbuffer) > 0:\n",
    "        feats[\"%s_%s\" % (\"buffer_word_1\", tokens[wbuffer[-1]])] = 1\n",
    "        feats[\"%s_%s\" % (\"buffer_tag_1\", postags[wbuffer[-1]])] = 1\n",
    "        feats[\"%s_%s_%s\" % (\"buffer_tag_word_1\", tokens[wbuffer[-1]], postags[wbuffer[-1]])] = 1\n",
    "\n",
    "    # word-pair features\n",
    "    if len(stack) > 1:\n",
    "        feats[\"%s_%s_%s_%s\" % (\"stack1_word_tag_stack2_tag\", tokens[stack[-1]], postags[stack[-1]], postags[stack[-2]])] = 1\n",
    "\n",
    "    return feats\n",
    "\n",
    "def get_oracles(filename):\n",
    "    \"\"\"\n",
    "    Get configurations, gold_transitions from all sentences\n",
    "    \"\"\"\n",
    "    with open(filename, encoding=\"utf8\") as f:\n",
    "        toks, tokens, postags = [], {}, {}\n",
    "        tokens[0] = \"ROOT\"\n",
    "        postags[0] = \"ROOT\"\n",
    "\n",
    "        # a list of all features for each transition step\n",
    "        feats = []\n",
    "        # a list of labels, e.g. SHIFT, LEFTARC_DEP_LABEL, RIGHTARC_DEP_LABEL\n",
    "        labels = []\n",
    "\n",
    "        for line in f:\n",
    "            cols = line.rstrip().split(\"\\t\")\n",
    "\n",
    "            if len(cols) < 2: # at the end of each sentence\n",
    "                if len(toks) > 0:\n",
    "                    if is_projective(toks): # only use projective trees\n",
    "                        # get all configurations and gold standard transitions\n",
    "                        configurations, gold_transitions = get_oracle(toks)\n",
    "\n",
    "                        for i in range(len(configurations)):\n",
    "                            feat = featurize_configuration(configurations[i], tokens, postags)\n",
    "                            label = gold_transitions[i]\n",
    "                            feats.append(feat)\n",
    "                            labels.append(label)\n",
    "\n",
    "                    # reset vars for the next sentence\n",
    "                    toks, tokens, postags = [], {}, {}\n",
    "                    tokens[0] = \"ROOT\"\n",
    "                    postags[0] = \"ROOT\"\n",
    "                continue\n",
    "\n",
    "            if cols[0].startswith(\"#\"):\n",
    "                continue\n",
    "\n",
    "            # construct the tuple for each word in the sentence\n",
    "            # for each word in the sentence\n",
    "            # idd: index of a word in a sentence, starting from 1\n",
    "            # tok: the word itself\n",
    "            # pos: pos tag for that word\n",
    "            # head: parent of the dependency\n",
    "            # lab: dependency relation label\n",
    "            idd, tok, pos, head, lab = int(cols[0]), cols[1], cols[4], int(cols[6]), cols[7]\n",
    "            toks.append((idd, tok, pos, head, lab))\n",
    "\n",
    "            # feature for training to predict the gold transition\n",
    "            tokens[idd], postags[idd] = tok, pos\n",
    "\n",
    "        return feats, labels\n",
    "\n",
    "def train(feats, labels):\n",
    "    \"\"\"\n",
    "    Train transition-based parsed to predict next action (labels)\n",
    "    given current configuration (featurized by feats)\n",
    "    Return the classifier trained using the logistic regression model\n",
    "    \"\"\"\n",
    "    global feature_vocab, label_vocab, fmax, reverse_labels, reverse_features\n",
    "\n",
    "    lid = 0 # label ID\n",
    "    D = len(feats) # each row of feats corresponds to a row in labels\n",
    "    feature_counts = Counter()\n",
    "\n",
    "    # build dictionary of labels\n",
    "    for i in range(D):\n",
    "        for f in feats[i]:\n",
    "            feature_counts[f] += 1\n",
    "\n",
    "        if labels[i] not in label_vocab:\n",
    "            label_vocab[labels[i]] = lid\n",
    "            lid += 1\n",
    "\n",
    "    # build dictionary of features\n",
    "    for f in feature_counts:\n",
    "        if feature_counts[f] > MINIMUM_FEAT_COUNT and f not in feature_vocab:\n",
    "            feature_vocab[f] = fmax\n",
    "            fmax += 1\n",
    "\n",
    "    # build reverse lookup for features and labels\n",
    "    reverse_labels = [None]*lid\n",
    "    for label in label_vocab:\n",
    "        reverse_labels[label_vocab[label]] = label\n",
    "\n",
    "    reverse_features = [None]*fmax\n",
    "    for feature in feature_vocab:\n",
    "        reverse_features[feature_vocab[feature]] = feature\n",
    "\n",
    "    # X is a D-by-fmax matrix, where each row represents\n",
    "    # features for a configuration / actions\n",
    "    # Y is a list of labels for all configurations\n",
    "    X = sparse.lil_matrix((D, fmax))\n",
    "    Y = []\n",
    "    for i in range(D):\n",
    "        for f in feats[i]:\n",
    "            if f in feature_vocab:\n",
    "                fid = feature_vocab[f]\n",
    "                X[i,fid] = 1\n",
    "        Y.append(label_vocab[labels[i]])\n",
    "\n",
    "    print (\"Docs: \", D, \"Features: \", fmax)\n",
    "    log_reg = linear_model.LogisticRegression(C=L2_REGULARIZATION_STRENGTH,\n",
    "                                              penalty='l2')\n",
    "\n",
    "    clf = grid_search.GridSearchCV(log_reg, {'C':(1e0,1e1)}, n_jobs=10)\n",
    "    log_reg = clf.fit(sparse.coo_matrix(X), Y).best_estimator_\n",
    "    print (\"Best C: %s\" % clf.best_estimator_)\n",
    "\n",
    "    return log_reg\n",
    "\n",
    "def parse(toks, logreg):\n",
    "    \"\"\"\n",
    "    parse sentence with trained model and return correctness measure\n",
    "    \"\"\"\n",
    "    tokens, postags = {}, {}\n",
    "    tokens[0] = \"ROOT\"\n",
    "    postags[0] = \"ROOT\"\n",
    "\n",
    "    heads, labels = {}, {}\n",
    "\n",
    "    wbuffer, stack, arcs = [], [], []\n",
    "    stack.append(0)\n",
    "\n",
    "    for position in reversed(toks):\n",
    "        # featurization\n",
    "        (idd, tok, pos, head, lab) = position\n",
    "        tokens[idd] = tok\n",
    "        postags[idd] = pos\n",
    "\n",
    "        # keep track of gold standards for performance evaluation\n",
    "        heads[idd], labels[idd] = head, lab\n",
    "\n",
    "        # update buffer\n",
    "        wbuffer.append(idd)\n",
    "\n",
    "    tree = {}\n",
    "    while len(wbuffer) >= 0:\n",
    "        if len(wbuffer) == 0 and len(stack) == 0: break\n",
    "        if len(wbuffer) == 0 and len(stack) == 1 and stack[0] == 0: break\n",
    "\n",
    "        feats = (featurize_configuration((wbuffer, stack, arcs), tokens, postags))\n",
    "        X = sparse.lil_matrix((1, fmax))\n",
    "        for f in feats:\n",
    "            if f in feature_vocab:\n",
    "                X[0,feature_vocab[f]]=1\n",
    "\n",
    "        predictions = logreg.predict_proba(X)\n",
    "        # your function will be called here\n",
    "        action_to_tree(tree, predictions, wbuffer, stack, arcs)\n",
    "\n",
    "    # correct_unlabeled: total number of correct (head, child) dependencies\n",
    "    # correct_labeled: total number of correctly *labeled* dependencies\n",
    "    correct_unlabeled, correct_labeled, total = 0, 0, 0\n",
    "\n",
    "    for child in tree:\n",
    "        (head, label) = tree[child]\n",
    "        if head == heads[child]:\n",
    "            correct_unlabeled += 1\n",
    "            if label == labels[child]: correct_labeled += 1\n",
    "        total += 1\n",
    "\n",
    "    return [correct_unlabeled, correct_labeled, total]\n",
    "\n",
    "def evaluate(filename, logreg):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of a parser against gold standard\n",
    "    \"\"\"\n",
    "    with open(filename, encoding=\"utf8\") as f:\n",
    "        toks=[]\n",
    "        totals = np.zeros(3)\n",
    "        for line in f:\n",
    "            cols=line.rstrip().split(\"\\t\")\n",
    "\n",
    "            if len(cols) < 2: # end of a sentence\n",
    "                if len(toks) > 0:\n",
    "                    if is_projective(toks):\n",
    "                        tots = np.array(parse(toks, logreg))\n",
    "                        totals += tots\n",
    "                        #print (\"%.3f\\t%.3f\\t%s\" % (totals[0]/totals[2], totals[1]/totals[2], totals))\n",
    "                    toks = []\n",
    "                continue\n",
    "\n",
    "            if cols[0].startswith(\"#\"):\n",
    "                continue\n",
    "\n",
    "            idd, tok, pos, head, lab = int(cols[0]), cols[1], cols[4], int(cols[6]), cols[7]\n",
    "            toks.append((idd, tok, pos, head, lab))\n",
    "        print(\"%.3f\\t%.3f\\t%s\" % (totals[0]/totals[2], totals[1]/totals[2], totals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs:  371858 Features:  47679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:553: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.738\t0.689\t[17447. 16282. 23625.]\n"
     ]
    }
   ],
   "source": [
    "feats, labels = get_oracles(\"train.projective.conll\")\n",
    "logreg = train(feats, labels)\n",
    "evaluate(\"dev.projective.conll\", logreg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
